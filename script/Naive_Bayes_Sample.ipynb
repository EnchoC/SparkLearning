{"cells":[{"cell_type":"code","source":["from collections import Counter\nfrom pyspark.sql import Row\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import Tokenizer\nfrom pyspark.ml.feature import HashingTF\nfrom pyspark.ml.feature import IDF\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.mllib.linalg import SparseVector\nfrom pyspark.mllib.classification import NaiveBayes\nfrom pyspark.ml.linalg import Vector as MLVector, Vectors as MLVectors\nfrom pyspark.mllib.linalg import Vector as MLLibVector, Vectors as MLLibVectors\nfrom pyspark.mllib.regression import LabeledPoint\nimport numpy as np\nimport pandas as pd"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["scRdd = sc.textFile('/FileStore/tables/C*') \\\n  .map(lambda x: x.split(',')) \\\n  .map(lambda x: Row(x[0], x[1]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["cols_name = ['label', 'text']\ntrain, test = scRdd.randomSplit([0.7, 0.3])\ntrainDf, testDf = train.toDF(cols_name), test.toDF(cols_name)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["tokenizer = Tokenizer().setInputCol('text').setOutputCol('words')\nhashingTF = HashingTF().setInputCol('words').setOutputCol('rawFeatures').setNumFeatures(500000)\npipeline = Pipeline().setStages([tokenizer, hashingTF])\nmodel = pipeline.fit(trainDf)\ntrainDf = model.transform(trainDf)\nidf = IDF().setInputCol('rawFeatures').setOutputCol('features')\nidfModel = idf.fit(trainDf)\nrescaleData = idfModel.transform(trainDf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["trainData = rescaleData.select('label','features') \\\n  .rdd \\\n  .map(lambda x: LabeledPoint(float(x[0]), MLLibVectors.fromML(x[1])))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["NBmodel = NaiveBayes().train(trainData, 1.0)\ntestDf = model.transform(testDf)\ntestData = idfModel.transform(testDf)\ntestData = testData.select('label','features') \\\n  .rdd \\\n  .map(lambda x: LabeledPoint(float(x[0]), MLLibVectors.fromML(x[1])))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["predData = testData.map(lambda x: (NBmodel.predict(x.features), x.label))\npreDAccracy = 1.0 * predData.filter(lambda x: x[0] == x[1]).count() / testData.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["print(preDAccracy)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.9105876393110436\n</div>"]}}],"execution_count":8}],"metadata":{"name":"MLlib pro","notebookId":3457555991250480},"nbformat":4,"nbformat_minor":0}
