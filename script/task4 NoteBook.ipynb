{"cells":[{"cell_type":"code","source":["from collections import Counter\nfrom pyspark.sql import Row\nfrom pyspark.ml.feature import Tokenizer\nfrom pyspark.ml.feature import HashingTF\nfrom pyspark.ml.feature import IDF\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\n\ndataPath = \"\"\"File uploaded to /FileStore/tables/C000008.txt\nFile uploaded to /FileStore/tables/C000010.txt\nFile uploaded to /FileStore/tables/C000013.txt\nFile uploaded to /FileStore/tables/C000014.txt\nFile uploaded to /FileStore/tables/C000007.txt\nFile uploaded to /FileStore/tables/C000016.txt\nFile uploaded to /FileStore/tables/C000020.txt\nFile uploaded to /FileStore/tables/C000022.txt\"\"\"\ndataPath = [i.split(' ')[-1] for i in dataPath.split('\\n')]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["columns = [\"category\", \"text\"]\ndf = sc.textFile(dataPath[0]) \\\n  .map(lambda x: x.split(',')) \\\n  .map(lambda x: (x[0], x[1])) \\\n  .toDF(columns)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["df.select(\"category\", 'text').take(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[62]: [Row(category=&#39;1&#39;, text=&#39;5月 09日 消息 深度 报告 权威 内参 证券 www.kl178.com 今日热点 五一 长假 过后 人民币 再度 逼近 8元 关口 8.0090 证券 市场 预期 美联储 将在 6月 暂停 导致 国际 市场上 美元 走势 疲软 高了 人民币 汇率 各方 预计 人民币 长期 持续 升值 不可避免 突破 8元 几成 定局 摩根 斯坦利 年底 人民币 升值 7.5元 此种 态势 预期 未来 市场 房地产板块 将在 人民币 升值 影响下 稳步 上扬 而对 外贸 依赖度 较高 的企业 则有 面临 业绩 下滑 危险 近期 8元 关口 心理 仍有 反复 投资者 不应 乐观 更多 详情 免费 咨询 021 64690729 登录 www.kl178.com 证券 资深 行业 研究员 提供 客观 深度 超前 投资 信息 作者 声明 机构 本人所 知情 范围内 机构 财产 利害 关系人 所述 文章内容 利害关系 本版 文章 纯属 个人观点 仅供参考 文责自负 读者 入市 风险 &#39;),\n Row(category=&#39;1&#39;, text=&#39;5月 09日 消息 深度 报告 权威 内参 证券 www.kl178.com 今日热点 五一 长假 过后 人民币 再度 逼近 8元 关口 8.0090 证券 市场 预期 美联储 将在 6月 暂停 导致 国际 市场上 美元 走势 疲软 高了 人民币 汇率 各方 预计 人民币 长期 持续 升值 不可避免 突破 8元 几成 定局 摩根 斯坦利 年底 人民币 升值 7.5元 此种 态势 预期 未来 市场 房地产板块 将在 人民币 升值 影响下 稳步 上扬 而对 外贸 依赖度 较高 的企业 则有 面临 业绩 下滑 危险 近期 8元 关口 心理 仍有 反复 投资者 不应 乐观 更多 详情 免费 咨询 021 64690729 登录 www.kl178.com 证券 资深 行业 研究员 提供 客观 深度 超前 投资 信息 作者 声明 机构 本人所 知情 范围内 机构 财产 利害 关系人 所述 文章内容 利害关系 本版 文章 纯属 个人观点 仅供参考 文责自负 读者 入市 风险 &#39;)]</div>"]}}],"execution_count":3},{"cell_type":"code","source":["tokenizer = Tokenizer().setInputCol('text').setOutputCol('word')\nwordData = tokenizer.transform(df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["wordData.select(\"category\",\"text\",\"word\").take(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[64]: [Row(category=&#39;1&#39;, text=&#39;5月 09日 消息 深度 报告 权威 内参 证券 www.kl178.com 今日热点 五一 长假 过后 人民币 再度 逼近 8元 关口 8.0090 证券 市场 预期 美联储 将在 6月 暂停 导致 国际 市场上 美元 走势 疲软 高了 人民币 汇率 各方 预计 人民币 长期 持续 升值 不可避免 突破 8元 几成 定局 摩根 斯坦利 年底 人民币 升值 7.5元 此种 态势 预期 未来 市场 房地产板块 将在 人民币 升值 影响下 稳步 上扬 而对 外贸 依赖度 较高 的企业 则有 面临 业绩 下滑 危险 近期 8元 关口 心理 仍有 反复 投资者 不应 乐观 更多 详情 免费 咨询 021 64690729 登录 www.kl178.com 证券 资深 行业 研究员 提供 客观 深度 超前 投资 信息 作者 声明 机构 本人所 知情 范围内 机构 财产 利害 关系人 所述 文章内容 利害关系 本版 文章 纯属 个人观点 仅供参考 文责自负 读者 入市 风险 &#39;, word=[&#39;5月&#39;, &#39;09日&#39;, &#39;消息&#39;, &#39;深度&#39;, &#39;报告&#39;, &#39;权威&#39;, &#39;内参&#39;, &#39;证券&#39;, &#39;www.kl178.com&#39;, &#39;今日热点&#39;, &#39;五一&#39;, &#39;长假&#39;, &#39;过后&#39;, &#39;人民币&#39;, &#39;再度&#39;, &#39;逼近&#39;, &#39;8元&#39;, &#39;关口&#39;, &#39;8.0090&#39;, &#39;证券&#39;, &#39;市场&#39;, &#39;预期&#39;, &#39;美联储&#39;, &#39;将在&#39;, &#39;6月&#39;, &#39;暂停&#39;, &#39;导致&#39;, &#39;国际&#39;, &#39;市场上&#39;, &#39;美元&#39;, &#39;走势&#39;, &#39;疲软&#39;, &#39;高了&#39;, &#39;人民币&#39;, &#39;汇率&#39;, &#39;各方&#39;, &#39;预计&#39;, &#39;人民币&#39;, &#39;长期&#39;, &#39;持续&#39;, &#39;升值&#39;, &#39;不可避免&#39;, &#39;突破&#39;, &#39;8元&#39;, &#39;几成&#39;, &#39;定局&#39;, &#39;摩根&#39;, &#39;斯坦利&#39;, &#39;年底&#39;, &#39;人民币&#39;, &#39;升值&#39;, &#39;7.5元&#39;, &#39;此种&#39;, &#39;态势&#39;, &#39;预期&#39;, &#39;未来&#39;, &#39;市场&#39;, &#39;房地产板块&#39;, &#39;将在&#39;, &#39;人民币&#39;, &#39;升值&#39;, &#39;影响下&#39;, &#39;稳步&#39;, &#39;上扬&#39;, &#39;而对&#39;, &#39;外贸&#39;, &#39;依赖度&#39;, &#39;较高&#39;, &#39;的企业&#39;, &#39;则有&#39;, &#39;面临&#39;, &#39;业绩&#39;, &#39;下滑&#39;, &#39;危险&#39;, &#39;近期&#39;, &#39;8元&#39;, &#39;关口&#39;, &#39;心理&#39;, &#39;仍有&#39;, &#39;反复&#39;, &#39;投资者&#39;, &#39;不应&#39;, &#39;乐观&#39;, &#39;更多&#39;, &#39;详情&#39;, &#39;免费&#39;, &#39;咨询&#39;, &#39;021&#39;, &#39;64690729&#39;, &#39;登录&#39;, &#39;www.kl178.com&#39;, &#39;证券&#39;, &#39;资深&#39;, &#39;行业&#39;, &#39;研究员&#39;, &#39;提供&#39;, &#39;客观&#39;, &#39;深度&#39;, &#39;超前&#39;, &#39;投资&#39;, &#39;信息&#39;, &#39;作者&#39;, &#39;声明&#39;, &#39;机构&#39;, &#39;本人所&#39;, &#39;知情&#39;, &#39;范围内&#39;, &#39;机构&#39;, &#39;财产&#39;, &#39;利害&#39;, &#39;关系人&#39;, &#39;所述&#39;, &#39;文章内容&#39;, &#39;利害关系&#39;, &#39;本版&#39;, &#39;文章&#39;, &#39;纯属&#39;, &#39;个人观点&#39;, &#39;仅供参考&#39;, &#39;文责自负&#39;, &#39;读者&#39;, &#39;入市&#39;, &#39;风险&#39;]),\n Row(category=&#39;1&#39;, text=&#39;5月 09日 消息 深度 报告 权威 内参 证券 www.kl178.com 今日热点 五一 长假 过后 人民币 再度 逼近 8元 关口 8.0090 证券 市场 预期 美联储 将在 6月 暂停 导致 国际 市场上 美元 走势 疲软 高了 人民币 汇率 各方 预计 人民币 长期 持续 升值 不可避免 突破 8元 几成 定局 摩根 斯坦利 年底 人民币 升值 7.5元 此种 态势 预期 未来 市场 房地产板块 将在 人民币 升值 影响下 稳步 上扬 而对 外贸 依赖度 较高 的企业 则有 面临 业绩 下滑 危险 近期 8元 关口 心理 仍有 反复 投资者 不应 乐观 更多 详情 免费 咨询 021 64690729 登录 www.kl178.com 证券 资深 行业 研究员 提供 客观 深度 超前 投资 信息 作者 声明 机构 本人所 知情 范围内 机构 财产 利害 关系人 所述 文章内容 利害关系 本版 文章 纯属 个人观点 仅供参考 文责自负 读者 入市 风险 &#39;, word=[&#39;5月&#39;, &#39;09日&#39;, &#39;消息&#39;, &#39;深度&#39;, &#39;报告&#39;, &#39;权威&#39;, &#39;内参&#39;, &#39;证券&#39;, &#39;www.kl178.com&#39;, &#39;今日热点&#39;, &#39;五一&#39;, &#39;长假&#39;, &#39;过后&#39;, &#39;人民币&#39;, &#39;再度&#39;, &#39;逼近&#39;, &#39;8元&#39;, &#39;关口&#39;, &#39;8.0090&#39;, &#39;证券&#39;, &#39;市场&#39;, &#39;预期&#39;, &#39;美联储&#39;, &#39;将在&#39;, &#39;6月&#39;, &#39;暂停&#39;, &#39;导致&#39;, &#39;国际&#39;, &#39;市场上&#39;, &#39;美元&#39;, &#39;走势&#39;, &#39;疲软&#39;, &#39;高了&#39;, &#39;人民币&#39;, &#39;汇率&#39;, &#39;各方&#39;, &#39;预计&#39;, &#39;人民币&#39;, &#39;长期&#39;, &#39;持续&#39;, &#39;升值&#39;, &#39;不可避免&#39;, &#39;突破&#39;, &#39;8元&#39;, &#39;几成&#39;, &#39;定局&#39;, &#39;摩根&#39;, &#39;斯坦利&#39;, &#39;年底&#39;, &#39;人民币&#39;, &#39;升值&#39;, &#39;7.5元&#39;, &#39;此种&#39;, &#39;态势&#39;, &#39;预期&#39;, &#39;未来&#39;, &#39;市场&#39;, &#39;房地产板块&#39;, &#39;将在&#39;, &#39;人民币&#39;, &#39;升值&#39;, &#39;影响下&#39;, &#39;稳步&#39;, &#39;上扬&#39;, &#39;而对&#39;, &#39;外贸&#39;, &#39;依赖度&#39;, &#39;较高&#39;, &#39;的企业&#39;, &#39;则有&#39;, &#39;面临&#39;, &#39;业绩&#39;, &#39;下滑&#39;, &#39;危险&#39;, &#39;近期&#39;, &#39;8元&#39;, &#39;关口&#39;, &#39;心理&#39;, &#39;仍有&#39;, &#39;反复&#39;, &#39;投资者&#39;, &#39;不应&#39;, &#39;乐观&#39;, &#39;更多&#39;, &#39;详情&#39;, &#39;免费&#39;, &#39;咨询&#39;, &#39;021&#39;, &#39;64690729&#39;, &#39;登录&#39;, &#39;www.kl178.com&#39;, &#39;证券&#39;, &#39;资深&#39;, &#39;行业&#39;, &#39;研究员&#39;, &#39;提供&#39;, &#39;客观&#39;, &#39;深度&#39;, &#39;超前&#39;, &#39;投资&#39;, &#39;信息&#39;, &#39;作者&#39;, &#39;声明&#39;, &#39;机构&#39;, &#39;本人所&#39;, &#39;知情&#39;, &#39;范围内&#39;, &#39;机构&#39;, &#39;财产&#39;, &#39;利害&#39;, &#39;关系人&#39;, &#39;所述&#39;, &#39;文章内容&#39;, &#39;利害关系&#39;, &#39;本版&#39;, &#39;文章&#39;, &#39;纯属&#39;, &#39;个人观点&#39;, &#39;仅供参考&#39;, &#39;文责自负&#39;, &#39;读者&#39;, &#39;入市&#39;, &#39;风险&#39;])]</div>"]}}],"execution_count":5},{"cell_type":"code","source":["hashingTF = HashingTF().setInputCol(\"word\").setOutputCol(\"feature\").setNumFeatures(100)\nfeatureData = hashingTF.transform(wordData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["featureData.show(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----------------------------+--------------------------+--------------------+\ncategory|                         text|                      word|             feature|\n+--------+-----------------------------+--------------------------+--------------------+\n       1|5月 09日 消息 深度 报告 权...|[5月, 09日, 消息, 深度,...|(100,[0,2,4,5,7,8...|\n       1|5月 09日 消息 深度 报告 权...|[5月, 09日, 消息, 深度,...|(100,[0,2,4,5,7,8...|\n+--------+-----------------------------+--------------------------+--------------------+\nonly showing top 2 rows\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["idf = IDF().setInputCol('feature').setOutputCol('IDFfeature')\nidfModel = idf.fit(featureData)\nresData = idfModel.transform(featureData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["resData.show(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----------------------------+--------------------------+--------------------+--------------------+\ncategory|                         text|                      word|             feature|          IDFfeature|\n+--------+-----------------------------+--------------------------+--------------------+--------------------+\n       1|5月 09日 消息 深度 报告 权...|[5月, 09日, 消息, 深度,...|(100,[0,2,4,5,7,8...|(100,[0,2,4,5,7,8...|\n       1|5月 09日 消息 深度 报告 权...|[5月, 09日, 消息, 深度,...|(100,[0,2,4,5,7,8...|(100,[0,2,4,5,7,8...|\n+--------+-----------------------------+--------------------------+--------------------+--------------------+\nonly showing top 2 rows\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["training = spark.createDataFrame([\n    (0, \"a b c d e spark\", 1.0),\n    (1, \"b d\", 0.0),\n    (2, \"spark f g h\", 1.0),\n    (3, \"hadoop mapreduce\", 0.0)\n], [\"id\", \"text\", \"label\"])\n\ntraining.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------------+-----+\n id|            text|label|\n+---+----------------+-----+\n  0| a b c d e spark|  1.0|\n  1|             b d|  0.0|\n  2|     spark f g h|  1.0|\n  3|hadoop mapreduce|  0.0|\n+---+----------------+-----+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(maxIter=10, regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\nmodel = pipeline.fit(training)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["test = spark.createDataFrame([\n    (4, \"spark i j k\"),\n    (5, \"l m n\"),\n    (6, \"spark hadoop spark\"),\n    (7, \"apache hadoop\")\n], [\"id\", \"text\"])\nprediction = model.transform(test)\nselected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\nfor row in selected.collect():\n    rid, text, prob, prediction = row\n    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(4, spark i j k) --&gt; prob=[0.1596407738787411,0.8403592261212589], prediction=1.000000\n(5, l m n) --&gt; prob=[0.8378325685476612,0.16216743145233878], prediction=0.000000\n(6, spark hadoop spark) --&gt; prob=[0.06926633132976266,0.9307336686702373], prediction=1.000000\n(7, apache hadoop) --&gt; prob=[0.9821575333444208,0.01784246665557917], prediction=0.000000\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.feature import Word2Vec\ndocumentDF = spark.createDataFrame([\n    (\"Hi I heard about Spark\".split(\" \"), ),\n    (\"I wish Java could use case classes\".split(\" \"), ),\n    (\"Logistic regression models are neat\".split(\" \"), )\n], [\"text\"])\n\nword2Vec = Word2Vec(vectorSize=3, minCount=0, \n                    inputCol=\"text\", outputCol=\"result\")\nmodel = word2Vec.fit(documentDF)\nresult = model.transform(documentDF)\nfor row in result.collect():\n    text, vector = row\n    print(\"Text: [%s] => \\nVector: %s\\n\" % (\", \".join(text), str(vector)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Text: [Hi, I, heard, about, Spark] =&gt; \nVector: [-0.03504721522331238,0.008686093054711819,0.030792908370494844]\n\nText: [I, wish, Java, could, use, case, classes] =&gt; \nVector: [0.02407229159559522,-0.047546425834298134,0.0704595111310482]\n\nText: [Logistic, regression, models, are, neat] =&gt; \nVector: [-0.003552869707345963,0.06767420209944248,0.038231285661458975]\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["from pyspark.ml.feature import ChiSqSelector\nfrom pyspark.ml.linalg import Vectors\ndf = spark.createDataFrame([\n    (7, Vectors.dense([0.0, 0.0, 18.0, 1.0]), 1.0,),\n    (8, Vectors.dense([0.0, 1.0, 12.0, 0.0]), 0.0,),\n    (9, Vectors.dense([1.0, 0.0, 15.0, 0.1]), 0.0,)\n], [\"id\", \"features\", \"clicked\"])\n\nselector = ChiSqSelector(numTopFeatures=1, featuresCol=\"features\",\n                         outputCol=\"selectedFeatures\", labelCol=\"clicked\")\nresult = selector.fit(df).transform(df)\nresult.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------------------+-------+----------------+\n id|          features|clicked|selectedFeatures|\n+---+------------------+-------+----------------+\n  7|[0.0,0.0,18.0,1.0]|    1.0|          [18.0]|\n  8|[0.0,1.0,12.0,0.0]|    0.0|          [12.0]|\n  9|[1.0,0.0,15.0,0.1]|    0.0|          [15.0]|\n+---+------------------+-------+----------------+\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":15}],"metadata":{"name":"MLlib for chinese","notebookId":1542797341665036},"nbformat":4,"nbformat_minor":0}
